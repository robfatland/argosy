{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4297c01-5fc5-48c5-8438-a4affd369c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First program: Create empty CSV files tracking profile status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf4980-7f32-47c7-9713-1135df6bdc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate CSV file tracking CTD temperature profile status for OOI RCA Slope Base shallow profiler.\n",
    "Creates rca_sb_ctd_temp_profile_status.csv with daily profile availability (2014-2025).\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Check if year is a leap year.\"\"\"\n",
    "    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "\n",
    "def get_days_in_year(year):\n",
    "    \"\"\"Get number of days in year.\"\"\"\n",
    "    return 366 if is_leap_year(year) else 365\n",
    "\n",
    "def julian_to_date(year, julian_day):\n",
    "    \"\"\"Convert Julian day to dd-MON-yyyy format.\"\"\"\n",
    "    date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=julian_day - 1)\n",
    "    return date.strftime(\"%d-%b-%Y\").upper()\n",
    "\n",
    "def generate_profile_status_csv():\n",
    "    \"\"\"Generate the profile status CSV file.\"\"\"\n",
    "    \n",
    "    output_file = Path(\"rca_sb_ctd_temp_profile_status.csv\")\n",
    "    \n",
    "    # Define year range\n",
    "    start_year = 2014\n",
    "    end_year = 2025\n",
    "    \n",
    "    # Column headers\n",
    "    headers = ['year', 'julian_day', 'date', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Total', 'Noon', 'Midnight']\n",
    "    \n",
    "    total_days = 0\n",
    "    total_profiles = 0\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write headers\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        # Generate rows for each year\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            days_in_year = get_days_in_year(year)\n",
    "            \n",
    "            for julian_day in range(1, days_in_year + 1):\n",
    "                date_str = julian_to_date(year, julian_day)\n",
    "                \n",
    "                # Initialize profile columns (1-9) as 0 (will be populated when processing actual data)\n",
    "                profiles = [0] * 9\n",
    "                \n",
    "                # Calculate totals\n",
    "                total_profiles_day = sum(profiles)\n",
    "                \n",
    "                # Placeholder values for noon and midnight profile indices\n",
    "                noon_profile = 0  # Will be determined from actual profile timing\n",
    "                midnight_profile = 0  # Will be determined from actual profile timing\n",
    "                \n",
    "                # Write row\n",
    "                row = [year, julian_day, date_str] + profiles + [total_profiles_day, noon_profile, midnight_profile]\n",
    "                writer.writerow(row)\n",
    "                \n",
    "                total_days += 1\n",
    "                total_profiles += total_profiles_day\n",
    "    \n",
    "    # Print diagnostics\n",
    "    print(f\"Generated {output_file}\")\n",
    "    print(f\"Total days: {total_days}\")\n",
    "    print(f\"Date range: {start_year} - {end_year}\")\n",
    "    print(f\"Years covered: {end_year - start_year + 1}\")\n",
    "    print(f\"Current mean profiles per day: {total_profiles / total_days:.2f}\")\n",
    "    print(f\"Expected profiles per day when populated: 9\")\n",
    "    print(f\"File ready for population with actual profile data\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_profile_status_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e211f3-6996-4bba-8e17-ba8bd862083b",
   "metadata": {},
   "source": [
    "## Update the profile status program, write extracted profile files, create a timeline file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e7354-c510-4962-9c28-57ada8ee6648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract individual temperature profiles from CTD NetCDF files to redux files.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_source_file(netcdf_file):\n",
    "    \"\"\"Analyze source NetCDF file time range and estimate profiles.\"\"\"\n",
    "    \n",
    "    ds = xr.open_dataset(netcdf_file)\n",
    "    ds = ds.swap_dims({'obs': 'time'})\n",
    "    \n",
    "    start_time = pd.to_datetime(ds.time.values[0])\n",
    "    end_time = pd.to_datetime(ds.time.values[-1])\n",
    "    \n",
    "    time_range_days = (end_time - start_time).days + 1\n",
    "    estimated_profiles = time_range_days * 9\n",
    "    \n",
    "    print(f\"=== SOURCE FILE ANALYSIS ===\")\n",
    "    print(f\"File: {netcdf_file}\")\n",
    "    print(f\"Start time: {start_time}\")\n",
    "    print(f\"End time: {end_time}\")\n",
    "    print(f\"Time range: {time_range_days} days\")\n",
    "    print(f\"Estimated profiles (9/day): {estimated_profiles}\")\n",
    "    print(f\"================================\\n\")\n",
    "    \n",
    "    return ds, start_time, end_time\n",
    "\n",
    "def load_profile_indices(year):\n",
    "    \"\"\"Load profile indices for given year.\"\"\"\n",
    "    profile_file = Path(f\"~/profileIndices/RS01SBPS_profiles_{year}.csv\").expanduser()\n",
    "    if not profile_file.exists():\n",
    "        return None\n",
    "    return pd.read_csv(profile_file)\n",
    "\n",
    "def extract_profiles(ds, start_time, end_time, output_dir):\n",
    "    \"\"\"Extract temperature profiles from NetCDF dataset.\"\"\"\n",
    "    \n",
    "    attempted = 0\n",
    "    successful = 0\n",
    "    \n",
    "    for year in range(start_time.year, end_time.year + 1):\n",
    "        profiles_df = load_profile_indices(year)\n",
    "        if profiles_df is None:\n",
    "            print(f\"No profile indices for {year}\")\n",
    "            continue\n",
    "            \n",
    "        daily_profiles = {}\n",
    "        \n",
    "        for _, profile_row in profiles_df.iterrows():\n",
    "            attempted += 1\n",
    "            \n",
    "            profile_index = profile_row['profile']\n",
    "            start_str = profile_row['start']\n",
    "            peak_str = profile_row['peak']\n",
    "            \n",
    "            start_time_profile = pd.to_datetime(start_str)\n",
    "            peak_time_profile = pd.to_datetime(peak_str)\n",
    "            \n",
    "            # Track daily profile sequence\n",
    "            date_key = start_time_profile.date()\n",
    "            if date_key not in daily_profiles:\n",
    "                daily_profiles[date_key] = 0\n",
    "            daily_profiles[date_key] += 1\n",
    "            daily_sequence = daily_profiles[date_key]\n",
    "            \n",
    "            try:\n",
    "                profile_data = ds.sel(time=slice(start_time_profile, peak_time_profile))\n",
    "                \n",
    "                if len(profile_data.time) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Check for sea_water_temperature data\n",
    "                if 'sea_water_temperature' not in profile_data.data_vars:\n",
    "                    continue\n",
    "                \n",
    "                # Create temperature dataset (rename variable)\n",
    "                temp_ds = xr.Dataset({\n",
    "                    'temperature': profile_data['sea_water_temperature']\n",
    "                })\n",
    "                \n",
    "                # Add depth coordinate if available\n",
    "                if 'depth' in profile_data.coords:\n",
    "                    temp_ds = temp_ds.assign_coords(depth=profile_data['depth'])\n",
    "                \n",
    "                # Generate filename: AAA_SSS_TTT_BBB_YYYY_DDD_PPPP_Q_VVVV.nc\n",
    "                julian_day = start_time_profile.timetuple().tm_yday\n",
    "                filename = f\"RCA_OSB_Profiler_Temp_{year}_{julian_day:03d}_{profile_index}_{daily_sequence}_V1.nc\"\n",
    "                output_path = output_dir / filename\n",
    "                \n",
    "                # Write file\n",
    "                temp_ds.to_netcdf(output_path)\n",
    "                successful += 1\n",
    "                \n",
    "                if successful % 50 == 0:\n",
    "                    print(f\"Extracted {successful} profiles...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing profile {profile_index}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return attempted, successful\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main processing function.\"\"\"\n",
    "    \n",
    "    output_dir = Path(\"~/redux\").expanduser()\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    ctd_file = Path(\"~/ooidata/rca/sb/scalar/2015_2025_ctd/deployment0004_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20180208T000000.840174-20180226T115959.391002.nc\").expanduser()\n",
    "    \n",
    "    if not ctd_file.exists():\n",
    "        print(f\"CTD file not found: {ctd_file}\")\n",
    "        return\n",
    "    \n",
    "    # Analyze source file first\n",
    "    ds, start_time, end_time = analyze_source_file(ctd_file)\n",
    "    \n",
    "    # Extract profiles\n",
    "    attempted, successful = extract_profiles(ds, start_time, end_time, output_dir)\n",
    "    \n",
    "    # Print diagnostics\n",
    "    print(f\"\\n=== EXTRACTION COMPLETE ===\")\n",
    "    print(f\"Profiles attempted: {attempted}\")\n",
    "    print(f\"Profiles successfully extracted: {successful}\")\n",
    "    print(f\"Success rate: {successful/attempted*100:.1f}%\" if attempted > 0 else \"No profiles attempted\")\n",
    "    print(f\"Redux files written to: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b0277c-20bf-4a80-a35f-4f1b016aa5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Data variables:\n",
       "    sea_water_pressure_qc_results                      (obs) uint8 ...\n",
       "    sea_water_pressure                                 (obs) float64 ...\n",
       "    sea_water_electrical_conductivity_qartod_results   (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen                         (obs) float64 ...\n",
       "    sea_water_pressure_qc_executed                     (obs) uint8 ...\n",
       "    sea_water_practical_salinity_qc_executed           (obs) uint8 ...\n",
       "    driver_timestamp                                   (obs) datetime64[ns] ...\n",
       "    id                                                 (obs) |S36 ...\n",
       "    conductivity                                       (obs) float64 ...\n",
       "    temperature                                        (obs) float64 ...\n",
       "    sea_water_temperature_qartod_results               (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen_qc_executed             (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen_qc_results              (obs) uint8 ...\n",
       "    pressure_temp                                      (obs) float64 ...\n",
       "    internal_timestamp                                 (obs) datetime64[ns] ...\n",
       "    corrected_dissolved_oxygen_qartod_executed         (obs) object ...\n",
       "    sea_water_electrical_conductivity_qc_executed      (obs) uint8 ...\n",
       "    sea_water_density_qc_results                       (obs) uint8 ...\n",
       "    ext_volt0                                          (obs) float64 ...\n",
       "    sea_water_practical_salinity_qartod_results        (obs) uint8 ...\n",
       "    sea_water_temperature_qc_results                   (obs) uint8 ...\n",
       "    sea_water_pressure_qartod_executed                 (obs) object ...\n",
       "    ingestion_timestamp                                (obs) datetime64[ns] ...\n",
       "    port_timestamp                                     (obs) datetime64[ns] ...\n",
       "    sea_water_practical_salinity                       (obs) float64 ...\n",
       "    pressure                                           (obs) float64 ...\n",
       "    sea_water_density_qc_executed                      (obs) uint8 ...\n",
       "    sea_water_temperature_qartod_executed              (obs) object ...\n",
       "    deployment                                         (obs) int32 ...\n",
       "    sea_water_practical_salinity_qc_results            (obs) uint8 ...\n",
       "    do_fast_sample-corrected_dissolved_oxygen          (obs) float64 ...\n",
       "    preferred_timestamp                                (obs) object ...\n",
       "    sea_water_electrical_conductivity                  (obs) float64 ...\n",
       "    corrected_dissolved_oxygen_qartod_results          (obs) uint8 ...\n",
       "    sea_water_electrical_conductivity_qc_results       (obs) uint8 ...\n",
       "    sea_water_temperature_qc_executed                  (obs) uint8 ...\n",
       "    sea_water_density                                  (obs) float64 ...\n",
       "    sea_water_pressure_qartod_results                  (obs) uint8 ...\n",
       "    sea_water_electrical_conductivity_qartod_executed  (obs) object ...\n",
       "    sea_water_temperature                              (obs) float64 ...\n",
       "    sea_water_practical_salinity_qartod_executed       (obs) object ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "#ds = xr.open_dataset('~/redux2018/RCA_sb_sp_temperature_2018_048_5440_9_V1.nc')\n",
    "ds_ctd = xr.open_dataset('~/ooidata/rca/sb/scalar/2016_ctd/deployment0002_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20160707T000000.194092-20160716T111049.607585.nc')\n",
    "ds_do  = xr.open_dataset('~/ooidata/rca/sb/scalar/2016_ctd/deployment0002_RS01SBPS-SF01A-2A-DOFSTA102-streamed-do_fast_sample_20160511T235959.098689-20160716T120000.633855.nc')\n",
    "ds_ctd.data_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea9c953-bc85-4f83-8fb2-052c97e5fead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Data variables:\n",
       "    preferred_timestamp                     (obs) object ...\n",
       "    ingestion_timestamp                     (obs) datetime64[ns] ...\n",
       "    port_timestamp                          (obs) datetime64[ns] ...\n",
       "    deployment                              (obs) int32 ...\n",
       "    corrected_dissolved_oxygen_qc_executed  (obs) uint8 ...\n",
       "    id                                      (obs) |S36 ...\n",
       "    corrected_dissolved_oxygen              (obs) float64 ...\n",
       "    corrected_dissolved_oxygen_qc_results   (obs) uint8 ...\n",
       "    internal_timestamp                      (obs) datetime64[ns] ...\n",
       "    ext_volt0                               (obs) float64 ...\n",
       "    driver_timestamp                        (obs) datetime64[ns] ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_do.data_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fffea-df49-422c-beb9-b2a9ed44e348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot temperature profiles with temperature on x-axis and depth on y-axis.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "    \n",
    "# Load the profile data\n",
    "ds = xr.open_dataset('~/redux/RCA_OSB_Profiler_Temp_2018_048_5440_9_V1.nc')\n",
    "\n",
    "# Extract temperature and depth\n",
    "temperature = ds['temperature'].values\n",
    "depth = ds['depth'].values\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(temperature, depth, 'b-', linewidth=2, marker='o', markersize=2)\n",
    "\n",
    "# Set up axes\n",
    "plt.xlabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.ylabel('Depth (m)', fontsize=12)\n",
    "plt.ylim(200, 0)  # 200m at bottom, 0m at top\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add title with filename\n",
    "profile_name = Path('~/redux/RCA_OSB_Profiler_Temp_2018_048_5440_9_V1.nc').stem\n",
    "plt.title(f'Temperature Profile: {profile_name}', fontsize=14)\n",
    "\n",
    "# Tight layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20a0e6-0b6d-47a5-b2c6-0774c5bca752",
   "metadata": {},
   "source": [
    "## Generate Temperature Mixed Layer Depth estimates: Interactive \n",
    "\n",
    "\n",
    "This code does not run in a Jupyter notebook: Something about the mouse events.\n",
    "It will run in IDLE or from the PowerShell command line. \n",
    "The file is called `tmld_selector.py`.\n",
    "The output file is `tmld_estimates.csv`.\n",
    "It lives in the home directory of the `argosy` repository.\n",
    "Eventually it will be renamed MLDSelector.py for Mixed Layer Depth Selector.\n",
    "\n",
    "\n",
    "There is a major **bug** in the code however: The bundle plotter gets the profile index\n",
    "wrong so the MLD shows up in the wrong place.\n",
    "\n",
    "\n",
    "`Use regular Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbed918-88a2-4480-aaf7-67872a2f0de2",
   "metadata": {},
   "source": [
    "## Shard a collection of source files into redux profile files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42873d85-37bc-4d5a-9fc3-3c8d292973c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for source folders...\n",
      "  2015_ctd: 19 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2015? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2016_ctd: 11 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2016? [y/n] (default y):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2018_ctd: 17 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2018? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2019_ctd: 15 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2019? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2020_ctd: 8 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2020? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected years: [2015, 2018, 2019, 2020]\n",
      "\n",
      "=== Processing 2015_ctd (19 files) ===\n",
      "  File 5/19\n",
      "  File 10/19\n",
      "  File 15/19\n",
      "\n",
      "=== Processing 2018_ctd (17 files) ===\n",
      "  File 5/17\n",
      "  File 10/17\n",
      "  File 15/17\n",
      "\n",
      "=== Processing 2019_ctd (15 files) ===\n",
      "  File 5/15\n",
      "  File 10/15\n",
      "  File 15/15\n",
      "\n",
      "=== Processing 2020_ctd (8 files) ===\n",
      "  File 5/8\n",
      "\n",
      "=== Processing Complete ===\n",
      "\n",
      "temperature:\n",
      "  Attempted: 7012\n",
      "  Written: 5894\n",
      "  Skipped (already exist): 212\n",
      "\n",
      "salinity:\n",
      "  Attempted: 7012\n",
      "  Written: 5894\n",
      "  Skipped (already exist): 212\n",
      "\n",
      "density:\n",
      "  Attempted: 7012\n",
      "  Written: 5894\n",
      "  Skipped (already exist): 212\n",
      "\n",
      "dissolvedoxygen:\n",
      "  Attempted: 7012\n",
      "  Written: 5894\n",
      "  Skipped (already exist): 212\n",
      "\n",
      "=== Files by Year ===\n",
      "\n",
      "2015:\n",
      "  temperature: 659\n",
      "  salinity: 659\n",
      "  density: 659\n",
      "  dissolvedoxygen: 659\n",
      "\n",
      "2018:\n",
      "  temperature: 1849\n",
      "  salinity: 1849\n",
      "  density: 1849\n",
      "  dissolvedoxygen: 1849\n",
      "\n",
      "2019:\n",
      "  temperature: 2105\n",
      "  salinity: 2105\n",
      "  density: 2105\n",
      "  dissolvedoxygen: 2105\n",
      "\n",
      "2020:\n",
      "  temperature: 1281\n",
      "  salinity: 1281\n",
      "  density: 1281\n",
      "  dissolvedoxygen: 1281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def get_input_with_default(prompt, default):\n",
    "    \"\"\"Get user input with default value.\"\"\"\n",
    "    response = input(f\"{prompt} \").strip().lower()\n",
    "    return response if response else default\n",
    "\n",
    "def load_profile_indices(year):\n",
    "    \"\"\"Load profile indices for given year.\"\"\"\n",
    "    profile_file = Path(f\"~/profileIndices/RS01SBPS_profiles_{year}.csv\").expanduser()\n",
    "    if not profile_file.exists():\n",
    "        return None\n",
    "    return pd.read_csv(profile_file)\n",
    "\n",
    "# Sensor mapping: input variable -> output variable name\n",
    "SENSOR_MAP = {\n",
    "    'sea_water_temperature': 'temperature',\n",
    "    'sea_water_practical_salinity': 'salinity',\n",
    "    'sea_water_density': 'density',\n",
    "    'do_fast_sample-corrected_dissolved_oxygen': 'dissolvedoxygen'\n",
    "}\n",
    "\n",
    "def process_multi_sensor_redux():\n",
    "    \"\"\"Process CTD files for multiple sensor types.\"\"\"\n",
    "    \n",
    "    # Scan for source folders\n",
    "    base_folder = Path(\"~/ooidata/rca/sb/scalar\").expanduser()\n",
    "    \n",
    "    print(\"Scanning for source folders...\")\n",
    "    available_years = []\n",
    "    for year in range(2014, 2027):\n",
    "        source_folder = base_folder / f\"{year}_ctd\"\n",
    "        if source_folder.exists():\n",
    "            file_count = len(list(source_folder.glob(\"*CTDPF*.nc\")))\n",
    "            if file_count > 0:\n",
    "                print(f\"  {year}_ctd: {file_count} files\")\n",
    "                response = get_input_with_default(f\"    Process {year}? [y/n] (default y):\", \"y\")\n",
    "                if response == 'y':\n",
    "                    available_years.append(year)\n",
    "    \n",
    "    if not available_years:\n",
    "        print(\"No years selected\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nSelected years: {available_years}\")\n",
    "    \n",
    "    # Create output directories\n",
    "    for year in range(2014, 2027):\n",
    "        output_dir = Path(f\"~/redux{year}\").expanduser()\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {sensor: {'attempted': 0, 'written': 0, 'skipped': 0} for sensor in SENSOR_MAP.values()}\n",
    "    \n",
    "    # Process each year\n",
    "    for folder_year in available_years:\n",
    "        source_folder = base_folder / f\"{folder_year}_ctd\"\n",
    "        ctd_files = sorted(list(source_folder.glob(\"*CTDPF*.nc\")))\n",
    "        \n",
    "        print(f\"\\n=== Processing {folder_year}_ctd ({len(ctd_files)} files) ===\")\n",
    "        \n",
    "        for file_idx, file_path in enumerate(ctd_files, 1):\n",
    "            if file_idx % 5 == 0:\n",
    "                print(f\"  File {file_idx}/{len(ctd_files)}\")\n",
    "            \n",
    "            try:\n",
    "                ds = xr.open_dataset(file_path)\n",
    "                ds = ds.swap_dims({'obs': 'time'})\n",
    "                \n",
    "                start_time = pd.to_datetime(ds.time.values[0])\n",
    "                end_time = pd.to_datetime(ds.time.values[-1])\n",
    "                \n",
    "                # Process each year in the file\n",
    "                for year in range(start_time.year, end_time.year + 1):\n",
    "                    profiles_df = load_profile_indices(year)\n",
    "                    if profiles_df is None:\n",
    "                        continue\n",
    "                    \n",
    "                    daily_profiles = {}\n",
    "                    \n",
    "                    for _, profile_row in profiles_df.iterrows():\n",
    "                        profile_index = profile_row['profile']\n",
    "                        start_str = profile_row['start']\n",
    "                        peak_str = profile_row['peak']\n",
    "                        \n",
    "                        start_time_profile = pd.to_datetime(start_str)\n",
    "                        peak_time_profile = pd.to_datetime(peak_str)\n",
    "                        \n",
    "                        # Track daily profile sequence\n",
    "                        date_key = start_time_profile.date()\n",
    "                        if date_key not in daily_profiles:\n",
    "                            daily_profiles[date_key] = 0\n",
    "                        daily_profiles[date_key] += 1\n",
    "                        daily_sequence = daily_profiles[date_key]\n",
    "                        \n",
    "                        try:\n",
    "                            profile_data = ds.sel(time=slice(start_time_profile, peak_time_profile))\n",
    "                            \n",
    "                            if len(profile_data.time) == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            # Determine output folder based on profile year\n",
    "                            profile_year = start_time_profile.year\n",
    "                            output_dir = Path(f\"~/redux{profile_year}\").expanduser()\n",
    "                            julian_day = start_time_profile.timetuple().tm_yday\n",
    "                            \n",
    "                            # Process each sensor type\n",
    "                            for input_var, output_var in SENSOR_MAP.items():\n",
    "                                stats[output_var]['attempted'] += 1\n",
    "                                \n",
    "                                # Generate filename\n",
    "                                filename = f\"RCA_sb_sp_{output_var}_{profile_year}_{julian_day:03d}_{profile_index}_{daily_sequence}_V1.nc\"\n",
    "                                output_path = output_dir / filename\n",
    "                                \n",
    "                                # Skip if file already exists\n",
    "                                if output_path.exists():\n",
    "                                    stats[output_var]['skipped'] += 1\n",
    "                                    continue\n",
    "                                \n",
    "                                # Check if variable exists in data\n",
    "                                if input_var not in profile_data.data_vars:\n",
    "                                    continue\n",
    "                                \n",
    "                                # Create dataset with renamed variable\n",
    "                                sensor_ds = xr.Dataset({\n",
    "                                    output_var: profile_data[input_var]\n",
    "                                })\n",
    "                                \n",
    "                                # Add depth coordinate if available\n",
    "                                if 'depth' in profile_data.coords:\n",
    "                                    sensor_ds = sensor_ds.assign_coords(depth=profile_data['depth'])\n",
    "                                \n",
    "                                # Remove unwanted variables\n",
    "                                for var in ['lat', 'lon', 'obs']:\n",
    "                                    if var in sensor_ds.coords:\n",
    "                                        sensor_ds = sensor_ds.drop_vars(var)\n",
    "                                    if var in sensor_ds.data_vars:\n",
    "                                        sensor_ds = sensor_ds.drop_vars(var)\n",
    "                                \n",
    "                                # Write file\n",
    "                                sensor_ds.to_netcdf(output_path)\n",
    "                                stats[output_var]['written'] += 1\n",
    "                            \n",
    "                        except Exception:\n",
    "                            continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n=== Processing Complete ===\")\n",
    "    for sensor, counts in stats.items():\n",
    "        print(f\"\\n{sensor}:\")\n",
    "        print(f\"  Attempted: {counts['attempted']}\")\n",
    "        print(f\"  Written: {counts['written']}\")\n",
    "        print(f\"  Skipped (already exist): {counts['skipped']}\")\n",
    "    \n",
    "    # Report files by year and sensor\n",
    "    print(\"\\n=== Files by Year ===\")\n",
    "    for year in range(2014, 2027):\n",
    "        output_dir = Path(f\"~/redux{year}\").expanduser()\n",
    "        if output_dir.exists():\n",
    "            sensor_counts = {}\n",
    "            for sensor in SENSOR_MAP.values():\n",
    "                count = len(list(output_dir.glob(f\"*_{sensor}_*.nc\")))\n",
    "                if count > 0:\n",
    "                    sensor_counts[sensor] = count\n",
    "            \n",
    "            if sensor_counts:\n",
    "                print(f\"\\n{year}:\")\n",
    "                for sensor, count in sensor_counts.items():\n",
    "                    print(f\"  {sensor}: {count}\")\n",
    "\n",
    "# Run the processing\n",
    "process_multi_sensor_redux()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
