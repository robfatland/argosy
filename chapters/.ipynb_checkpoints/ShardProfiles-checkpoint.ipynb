{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4297c01-5fc5-48c5-8438-a4affd369c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profile tracking (on pause for now)\n",
    "\n",
    "\n",
    "Here the idea is that for a site (like Oregon Slope Base) the system has capacity\n",
    "for 365 * 9 profiles; and we want to have a record of what was actually present \n",
    "in the data system. This is worked up as a CSV table; a handy metadata\n",
    "reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf4980-7f32-47c7-9713-1135df6bdc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate CSV file tracking CTD temperature profile status for OOI RCA Slope Base shallow profiler.\n",
    "Creates rca_sb_ctd_temp_profile_status.csv with daily profile availability (2014-2025).\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def is_leap_year(year):\n",
    "    \"\"\"Check if year is a leap year.\"\"\"\n",
    "    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "\n",
    "def get_days_in_year(year):\n",
    "    \"\"\"Get number of days in year.\"\"\"\n",
    "    return 366 if is_leap_year(year) else 365\n",
    "\n",
    "def julian_to_date(year, julian_day):\n",
    "    \"\"\"Convert Julian day to dd-MON-yyyy format.\"\"\"\n",
    "    date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=julian_day - 1)\n",
    "    return date.strftime(\"%d-%b-%Y\").upper()\n",
    "\n",
    "def generate_profile_status_csv():\n",
    "    \"\"\"Generate the profile status CSV file.\"\"\"\n",
    "    \n",
    "    output_file = Path(\"rca_sb_ctd_temp_profile_status.csv\")\n",
    "    \n",
    "    # Define year range\n",
    "    start_year = 2014\n",
    "    end_year = 2025\n",
    "    \n",
    "    # Column headers\n",
    "    headers = ['year', 'julian_day', 'date', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Total', 'Noon', 'Midnight']\n",
    "    \n",
    "    total_days = 0\n",
    "    total_profiles = 0\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write headers\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        # Generate rows for each year\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            days_in_year = get_days_in_year(year)\n",
    "            \n",
    "            for julian_day in range(1, days_in_year + 1):\n",
    "                date_str = julian_to_date(year, julian_day)\n",
    "                \n",
    "                # Initialize profile columns (1-9) as 0 (will be populated when processing actual data)\n",
    "                profiles = [0] * 9\n",
    "                \n",
    "                # Calculate totals\n",
    "                total_profiles_day = sum(profiles)\n",
    "                \n",
    "                # Placeholder values for noon and midnight profile indices\n",
    "                noon_profile = 0  # Will be determined from actual profile timing\n",
    "                midnight_profile = 0  # Will be determined from actual profile timing\n",
    "                \n",
    "                # Write row\n",
    "                row = [year, julian_day, date_str] + profiles + [total_profiles_day, noon_profile, midnight_profile]\n",
    "                writer.writerow(row)\n",
    "                \n",
    "                total_days += 1\n",
    "                total_profiles += total_profiles_day\n",
    "    \n",
    "    # Print diagnostics\n",
    "    print(f\"Generated {output_file}\")\n",
    "    print(f\"Total days: {total_days}\")\n",
    "    print(f\"Date range: {start_year} - {end_year}\")\n",
    "    print(f\"Years covered: {end_year - start_year + 1}\")\n",
    "    print(f\"Current mean profiles per day: {total_profiles / total_days:.2f}\")\n",
    "    print(f\"Expected profiles per day when populated: 9\")\n",
    "    print(f\"File ready for population with actual profile data\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_profile_status_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e211f3-6996-4bba-8e17-ba8bd862083b",
   "metadata": {},
   "source": [
    "## Update the profile status program, write extracted profile files, create a timeline file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e7354-c510-4962-9c28-57ada8ee6648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract individual temperature profiles from CTD NetCDF files to redux files.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_source_file(netcdf_file):\n",
    "    \"\"\"Analyze source NetCDF file time range and estimate profiles.\"\"\"\n",
    "    \n",
    "    ds = xr.open_dataset(netcdf_file)\n",
    "    ds = ds.swap_dims({'obs': 'time'})\n",
    "    \n",
    "    start_time = pd.to_datetime(ds.time.values[0])\n",
    "    end_time = pd.to_datetime(ds.time.values[-1])\n",
    "    \n",
    "    time_range_days = (end_time - start_time).days + 1\n",
    "    estimated_profiles = time_range_days * 9\n",
    "    \n",
    "    print(f\"=== SOURCE FILE ANALYSIS ===\")\n",
    "    print(f\"File: {netcdf_file}\")\n",
    "    print(f\"Start time: {start_time}\")\n",
    "    print(f\"End time: {end_time}\")\n",
    "    print(f\"Time range: {time_range_days} days\")\n",
    "    print(f\"Estimated profiles (9/day): {estimated_profiles}\")\n",
    "    print(f\"================================\\n\")\n",
    "    \n",
    "    return ds, start_time, end_time\n",
    "\n",
    "def load_profile_indices(year):\n",
    "    \"\"\"Load profile indices for given year.\"\"\"\n",
    "    profile_file = Path(f\"~/profileIndices/RS01SBPS_profiles_{year}.csv\").expanduser()\n",
    "    if not profile_file.exists():\n",
    "        return None\n",
    "    return pd.read_csv(profile_file)\n",
    "\n",
    "def extract_profiles(ds, start_time, end_time, output_dir):\n",
    "    \"\"\"Extract temperature profiles from NetCDF dataset.\"\"\"\n",
    "    \n",
    "    attempted = 0\n",
    "    successful = 0\n",
    "    \n",
    "    for year in range(start_time.year, end_time.year + 1):\n",
    "        profiles_df = load_profile_indices(year)\n",
    "        if profiles_df is None:\n",
    "            print(f\"No profile indices for {year}\")\n",
    "            continue\n",
    "            \n",
    "        daily_profiles = {}\n",
    "        \n",
    "        for _, profile_row in profiles_df.iterrows():\n",
    "            attempted += 1\n",
    "            \n",
    "            profile_index = profile_row['profile']\n",
    "            start_str = profile_row['start']\n",
    "            peak_str = profile_row['peak']\n",
    "            \n",
    "            start_time_profile = pd.to_datetime(start_str)\n",
    "            peak_time_profile = pd.to_datetime(peak_str)\n",
    "            \n",
    "            # Track daily profile sequence\n",
    "            date_key = start_time_profile.date()\n",
    "            if date_key not in daily_profiles:\n",
    "                daily_profiles[date_key] = 0\n",
    "            daily_profiles[date_key] += 1\n",
    "            daily_sequence = daily_profiles[date_key]\n",
    "            \n",
    "            try:\n",
    "                profile_data = ds.sel(time=slice(start_time_profile, peak_time_profile))\n",
    "                \n",
    "                if len(profile_data.time) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Check for sea_water_temperature data\n",
    "                if 'sea_water_temperature' not in profile_data.data_vars:\n",
    "                    continue\n",
    "                \n",
    "                # Create temperature dataset (rename variable)\n",
    "                temp_ds = xr.Dataset({\n",
    "                    'temperature': profile_data['sea_water_temperature']\n",
    "                })\n",
    "                \n",
    "                # Add depth coordinate if available\n",
    "                if 'depth' in profile_data.coords:\n",
    "                    temp_ds = temp_ds.assign_coords(depth=profile_data['depth'])\n",
    "                \n",
    "                # Generate filename: AAA_SSS_TTT_BBB_YYYY_DDD_PPPP_Q_VVVV.nc\n",
    "                julian_day = start_time_profile.timetuple().tm_yday\n",
    "                filename = f\"RCA_OSB_Profiler_Temp_{year}_{julian_day:03d}_{profile_index}_{daily_sequence}_V1.nc\"\n",
    "                output_path = output_dir / filename\n",
    "                \n",
    "                # Write file\n",
    "                temp_ds.to_netcdf(output_path)\n",
    "                successful += 1\n",
    "                \n",
    "                if successful % 50 == 0:\n",
    "                    print(f\"Extracted {successful} profiles...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing profile {profile_index}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return attempted, successful\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main processing function.\"\"\"\n",
    "    \n",
    "    output_dir = Path(\"~/redux\").expanduser()\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    ctd_file = Path(\"~/ooidata/rca/sb/scalar/2015_2025_ctd/deployment0004_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20180208T000000.840174-20180226T115959.391002.nc\").expanduser()\n",
    "    \n",
    "    if not ctd_file.exists():\n",
    "        print(f\"CTD file not found: {ctd_file}\")\n",
    "        return\n",
    "    \n",
    "    # Analyze source file first\n",
    "    ds, start_time, end_time = analyze_source_file(ctd_file)\n",
    "    \n",
    "    # Extract profiles\n",
    "    attempted, successful = extract_profiles(ds, start_time, end_time, output_dir)\n",
    "    \n",
    "    # Print diagnostics\n",
    "    print(f\"\\n=== EXTRACTION COMPLETE ===\")\n",
    "    print(f\"Profiles attempted: {attempted}\")\n",
    "    print(f\"Profiles successfully extracted: {successful}\")\n",
    "    print(f\"Success rate: {successful/attempted*100:.1f}%\" if attempted > 0 else \"No profiles attempted\")\n",
    "    print(f\"Redux files written to: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b0277c-20bf-4a80-a35f-4f1b016aa5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Data variables:\n",
       "    sea_water_pressure_qc_results                      (obs) uint8 ...\n",
       "    sea_water_pressure                                 (obs) float64 ...\n",
       "    sea_water_electrical_conductivity_qartod_results   (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen                         (obs) float64 ...\n",
       "    sea_water_pressure_qc_executed                     (obs) uint8 ...\n",
       "    sea_water_practical_salinity_qc_executed           (obs) uint8 ...\n",
       "    driver_timestamp                                   (obs) datetime64[ns] ...\n",
       "    id                                                 (obs) |S36 ...\n",
       "    conductivity                                       (obs) float64 ...\n",
       "    temperature                                        (obs) float64 ...\n",
       "    sea_water_temperature_qartod_results               (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen_qc_executed             (obs) uint8 ...\n",
       "    corrected_dissolved_oxygen_qc_results              (obs) uint8 ...\n",
       "    pressure_temp                                      (obs) float64 ...\n",
       "    internal_timestamp                                 (obs) datetime64[ns] ...\n",
       "    corrected_dissolved_oxygen_qartod_executed         (obs) object ...\n",
       "    sea_water_electrical_conductivity_qc_executed      (obs) uint8 ...\n",
       "    sea_water_density_qc_results                       (obs) uint8 ...\n",
       "    ext_volt0                                          (obs) float64 ...\n",
       "    sea_water_practical_salinity_qartod_results        (obs) uint8 ...\n",
       "    sea_water_temperature_qc_results                   (obs) uint8 ...\n",
       "    sea_water_pressure_qartod_executed                 (obs) object ...\n",
       "    ingestion_timestamp                                (obs) datetime64[ns] ...\n",
       "    port_timestamp                                     (obs) datetime64[ns] ...\n",
       "    sea_water_practical_salinity                       (obs) float64 ...\n",
       "    pressure                                           (obs) float64 ...\n",
       "    sea_water_density_qc_executed                      (obs) uint8 ...\n",
       "    sea_water_temperature_qartod_executed              (obs) object ...\n",
       "    deployment                                         (obs) int32 ...\n",
       "    sea_water_practical_salinity_qc_results            (obs) uint8 ...\n",
       "    do_fast_sample-corrected_dissolved_oxygen          (obs) float64 ...\n",
       "    preferred_timestamp                                (obs) object ...\n",
       "    sea_water_electrical_conductivity                  (obs) float64 ...\n",
       "    corrected_dissolved_oxygen_qartod_results          (obs) uint8 ...\n",
       "    sea_water_electrical_conductivity_qc_results       (obs) uint8 ...\n",
       "    sea_water_temperature_qc_executed                  (obs) uint8 ...\n",
       "    sea_water_density                                  (obs) float64 ...\n",
       "    sea_water_pressure_qartod_results                  (obs) uint8 ...\n",
       "    sea_water_electrical_conductivity_qartod_executed  (obs) object ...\n",
       "    sea_water_temperature                              (obs) float64 ...\n",
       "    sea_water_practical_salinity_qartod_executed       (obs) object ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "#ds = xr.open_dataset('~/redux2018/RCA_sb_sp_temperature_2018_048_5440_9_V1.nc')\n",
    "ds_ctd = xr.open_dataset('~/ooidata/rca/sb/scalar/2016_ctd/deployment0002_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20160707T000000.194092-20160716T111049.607585.nc')\n",
    "ds_do  = xr.open_dataset('~/ooidata/rca/sb/scalar/2016_ctd/deployment0002_RS01SBPS-SF01A-2A-DOFSTA102-streamed-do_fast_sample_20160511T235959.098689-20160716T120000.633855.nc')\n",
    "ds_ctd.data_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea9c953-bc85-4f83-8fb2-052c97e5fead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Data variables:\n",
       "    preferred_timestamp                     (obs) object ...\n",
       "    ingestion_timestamp                     (obs) datetime64[ns] ...\n",
       "    port_timestamp                          (obs) datetime64[ns] ...\n",
       "    deployment                              (obs) int32 ...\n",
       "    corrected_dissolved_oxygen_qc_executed  (obs) uint8 ...\n",
       "    id                                      (obs) |S36 ...\n",
       "    corrected_dissolved_oxygen              (obs) float64 ...\n",
       "    corrected_dissolved_oxygen_qc_results   (obs) uint8 ...\n",
       "    internal_timestamp                      (obs) datetime64[ns] ...\n",
       "    ext_volt0                               (obs) float64 ...\n",
       "    driver_timestamp                        (obs) datetime64[ns] ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_do.data_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fffea-df49-422c-beb9-b2a9ed44e348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot temperature profiles with temperature on x-axis and depth on y-axis.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "    \n",
    "# Load the profile data\n",
    "ds = xr.open_dataset('~/redux/RCA_OSB_Profiler_Temp_2018_048_5440_9_V1.nc')\n",
    "\n",
    "# Extract temperature and depth\n",
    "temperature = ds['temperature'].values\n",
    "depth = ds['depth'].values\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(temperature, depth, 'b-', linewidth=2, marker='o', markersize=2)\n",
    "\n",
    "# Set up axes\n",
    "plt.xlabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.ylabel('Depth (m)', fontsize=12)\n",
    "plt.ylim(200, 0)  # 200m at bottom, 0m at top\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add title with filename\n",
    "profile_name = Path('~/redux/RCA_OSB_Profiler_Temp_2018_048_5440_9_V1.nc').stem\n",
    "plt.title(f'Temperature Profile: {profile_name}', fontsize=14)\n",
    "\n",
    "# Tight layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20a0e6-0b6d-47a5-b2c6-0774c5bca752",
   "metadata": {},
   "source": [
    "## Generate Temperature Mixed Layer Depth estimates: Interactive \n",
    "\n",
    "\n",
    "This code does not run in a Jupyter notebook: Something about the mouse events.\n",
    "It will run in IDLE or from the PowerShell command line. \n",
    "The file is called `tmld_selector.py`.\n",
    "The output file is `tmld_estimates.csv`.\n",
    "It lives in the home directory of the `argosy` repository.\n",
    "Eventually it will be renamed MLDSelector.py for Mixed Layer Depth Selector.\n",
    "\n",
    "\n",
    "There is a major **bug** in the code however: The bundle plotter gets the profile index\n",
    "wrong so the MLD shows up in the wrong place.\n",
    "\n",
    "\n",
    "`Use regular Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbed918-88a2-4480-aaf7-67872a2f0de2",
   "metadata": {},
   "source": [
    "## Shard a collection of source files into redux profile files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42873d85-37bc-4d5a-9fc3-3c8d292973c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for source folders...\n",
      "  2015_ctd: 19 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2015? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2016_ctd: 20 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2016? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2017_ctd: 10 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2017? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2018_ctd: 17 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2018? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2019_ctd: 15 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2019? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2020_ctd: 8 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2020? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2021_ctd: 19 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2021? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2022_ctd: 19 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2022? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2023_ctd: 10 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2023? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2024_ctd: 19 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2024? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2025_ctd: 21 files\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    Process 2025? [y/n] (default y):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected years: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
      "\n",
      "=== Processing 2015_ctd (19 files) ===\n",
      "  File 5/19\n",
      "  File 10/19\n",
      "  File 15/19\n",
      "\n",
      "=== Processing 2016_ctd (20 files) ===\n",
      "  File 5/20\n",
      "  File 10/20\n",
      "  File 15/20\n",
      "  File 20/20\n",
      "\n",
      "=== Processing 2017_ctd (10 files) ===\n",
      "  File 5/10\n",
      "  File 10/10\n",
      "\n",
      "=== Processing 2018_ctd (17 files) ===\n",
      "  File 5/17\n",
      "  File 10/17\n",
      "  File 15/17\n",
      "\n",
      "=== Processing 2019_ctd (15 files) ===\n",
      "  File 5/15\n",
      "  File 10/15\n",
      "  File 15/15\n",
      "\n",
      "=== Processing 2020_ctd (8 files) ===\n",
      "  File 5/8\n",
      "\n",
      "=== Processing 2021_ctd (19 files) ===\n",
      "  File 5/19\n",
      "  File 10/19\n",
      "  File 15/19\n",
      "\n",
      "=== Processing 2022_ctd (19 files) ===\n",
      "  File 5/19\n",
      "  File 10/19\n",
      "  File 15/19\n",
      "\n",
      "=== Processing 2023_ctd (10 files) ===\n",
      "  File 5/10\n",
      "  File 10/10\n",
      "\n",
      "=== Processing 2024_ctd (19 files) ===\n",
      "  File 5/19\n",
      "  File 10/19\n",
      "  File 15/19\n",
      "\n",
      "=== Processing 2025_ctd (21 files) ===\n",
      "  File 5/21\n",
      "  File 10/21\n",
      "  File 15/21\n",
      "  File 20/21\n",
      "\n",
      "=== Processing Complete ===\n",
      "\n",
      "temperature:\n",
      "  Attempted: 21704\n",
      "  Written: 20553\n",
      "  Skipped (already exist): 245\n",
      "\n",
      "salinity:\n",
      "  Attempted: 21704\n",
      "  Written: 20553\n",
      "  Skipped (already exist): 245\n",
      "\n",
      "density:\n",
      "  Attempted: 21704\n",
      "  Written: 20553\n",
      "  Skipped (already exist): 245\n",
      "\n",
      "dissolvedoxygen:\n",
      "  Attempted: 21704\n",
      "  Written: 20553\n",
      "  Skipped (already exist): 245\n",
      "\n",
      "=== Files by Year ===\n",
      "\n",
      "2015:\n",
      "  temperature: 659\n",
      "  salinity: 659\n",
      "  density: 659\n",
      "  dissolvedoxygen: 659\n",
      "\n",
      "2016:\n",
      "  temperature: 2953\n",
      "  salinity: 2953\n",
      "  density: 2953\n",
      "  dissolvedoxygen: 2953\n",
      "\n",
      "2017:\n",
      "  temperature: 1409\n",
      "  salinity: 1409\n",
      "  density: 1409\n",
      "  dissolvedoxygen: 1409\n",
      "\n",
      "2018:\n",
      "  temperature: 1849\n",
      "  salinity: 1849\n",
      "  density: 1849\n",
      "  dissolvedoxygen: 1849\n",
      "\n",
      "2019:\n",
      "  temperature: 2105\n",
      "  salinity: 2105\n",
      "  density: 2105\n",
      "  dissolvedoxygen: 2105\n",
      "\n",
      "2020:\n",
      "  temperature: 1281\n",
      "  salinity: 1281\n",
      "  density: 1281\n",
      "  dissolvedoxygen: 1281\n",
      "\n",
      "2021:\n",
      "  temperature: 2690\n",
      "  salinity: 2690\n",
      "  density: 2690\n",
      "  dissolvedoxygen: 2690\n",
      "\n",
      "2022:\n",
      "  temperature: 2193\n",
      "  salinity: 2193\n",
      "  density: 2193\n",
      "  dissolvedoxygen: 2193\n",
      "\n",
      "2023:\n",
      "  temperature: 785\n",
      "  salinity: 785\n",
      "  density: 785\n",
      "  dissolvedoxygen: 785\n",
      "\n",
      "2024:\n",
      "  temperature: 1802\n",
      "  salinity: 1802\n",
      "  density: 1802\n",
      "  dissolvedoxygen: 1802\n",
      "\n",
      "2025:\n",
      "  temperature: 2827\n",
      "  salinity: 2827\n",
      "  density: 2827\n",
      "  dissolvedoxygen: 2827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def get_input_with_default(prompt, default):\n",
    "    \"\"\"Get user input with default value.\"\"\"\n",
    "    response = input(f\"{prompt} \").strip().lower()\n",
    "    return response if response else default\n",
    "\n",
    "def load_profile_indices(year):\n",
    "    \"\"\"Load profile indices for given year.\"\"\"\n",
    "    profile_file = Path(f\"~/profileIndices/RS01SBPS_profiles_{year}.csv\").expanduser()\n",
    "    if not profile_file.exists():\n",
    "        return None\n",
    "    return pd.read_csv(profile_file)\n",
    "\n",
    "# Sensor mapping: input variable -> output variable name\n",
    "SENSOR_MAP = {\n",
    "    'sea_water_temperature': 'temperature',\n",
    "    'sea_water_practical_salinity': 'salinity',\n",
    "    'sea_water_density': 'density',\n",
    "    'corrected_dissolved_oxygen': 'dissolvedoxygen'\n",
    "}\n",
    "\n",
    "def process_multi_sensor_redux():\n",
    "    \"\"\"Process CTD files for multiple sensor types.\"\"\"\n",
    "    \n",
    "    # Scan for source folders\n",
    "    base_folder = Path(\"~/ooidata/rca/sb/scalar\").expanduser()\n",
    "    \n",
    "    print(\"Scanning for source folders...\")\n",
    "    available_years = []\n",
    "    for year in range(2014, 2027):\n",
    "        source_folder = base_folder / f\"{year}_ctd\"\n",
    "        if source_folder.exists():\n",
    "            file_count = len(list(source_folder.glob(\"*CTDPF*.nc\")))\n",
    "            if file_count > 0:\n",
    "                print(f\"  {year}_ctd: {file_count} files\")\n",
    "                response = get_input_with_default(f\"    Process {year}? [y/n] (default y):\", \"y\")\n",
    "                if response == 'y':\n",
    "                    available_years.append(year)\n",
    "    \n",
    "    if not available_years:\n",
    "        print(\"No years selected\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nSelected years: {available_years}\")\n",
    "    \n",
    "    # Create output directories\n",
    "    for year in range(2014, 2027):\n",
    "        output_dir = Path(f\"~/redux{year}\").expanduser()\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {sensor: {'attempted': 0, 'written': 0, 'skipped': 0} for sensor in SENSOR_MAP.values()}\n",
    "    \n",
    "    # Process each year\n",
    "    for folder_year in available_years:\n",
    "        source_folder = base_folder / f\"{folder_year}_ctd\"\n",
    "        ctd_files = sorted(list(source_folder.glob(\"*CTDPF*.nc\")))\n",
    "        \n",
    "        print(f\"\\n=== Processing {folder_year}_ctd ({len(ctd_files)} files) ===\")\n",
    "        \n",
    "        for file_idx, file_path in enumerate(ctd_files, 1):\n",
    "            if file_idx % 5 == 0:\n",
    "                print(f\"  File {file_idx}/{len(ctd_files)}\")\n",
    "            \n",
    "            try:\n",
    "                ds = xr.open_dataset(file_path)\n",
    "                ds = ds.swap_dims({'obs': 'time'})\n",
    "                \n",
    "                start_time = pd.to_datetime(ds.time.values[0])\n",
    "                end_time = pd.to_datetime(ds.time.values[-1])\n",
    "                \n",
    "                # Process each year in the file\n",
    "                for year in range(start_time.year, end_time.year + 1):\n",
    "                    profiles_df = load_profile_indices(year)\n",
    "                    if profiles_df is None:\n",
    "                        continue\n",
    "                    \n",
    "                    daily_profiles = {}\n",
    "                    \n",
    "                    for _, profile_row in profiles_df.iterrows():\n",
    "                        profile_index = profile_row['profile']\n",
    "                        start_str = profile_row['start']\n",
    "                        peak_str = profile_row['peak']\n",
    "                        \n",
    "                        start_time_profile = pd.to_datetime(start_str)\n",
    "                        peak_time_profile = pd.to_datetime(peak_str)\n",
    "                        \n",
    "                        # Track daily profile sequence\n",
    "                        date_key = start_time_profile.date()\n",
    "                        if date_key not in daily_profiles:\n",
    "                            daily_profiles[date_key] = 0\n",
    "                        daily_profiles[date_key] += 1\n",
    "                        daily_sequence = daily_profiles[date_key]\n",
    "                        \n",
    "                        try:\n",
    "                            profile_data = ds.sel(time=slice(start_time_profile, peak_time_profile))\n",
    "                            \n",
    "                            if len(profile_data.time) == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            # Determine output folder based on profile year\n",
    "                            profile_year = start_time_profile.year\n",
    "                            output_dir = Path(f\"~/redux{profile_year}\").expanduser()\n",
    "                            julian_day = start_time_profile.timetuple().tm_yday\n",
    "                            \n",
    "                            # Process each sensor type\n",
    "                            for input_var, output_var in SENSOR_MAP.items():\n",
    "                                stats[output_var]['attempted'] += 1\n",
    "                                \n",
    "                                # Generate filename\n",
    "                                filename = f\"RCA_sb_sp_{output_var}_{profile_year}_{julian_day:03d}_{profile_index}_{daily_sequence}_V1.nc\"\n",
    "                                output_path = output_dir / filename\n",
    "                                \n",
    "                                # Skip if file already exists\n",
    "                                if output_path.exists():\n",
    "                                    stats[output_var]['skipped'] += 1\n",
    "                                    continue\n",
    "                                \n",
    "                                # Check if variable exists in data\n",
    "                                if input_var not in profile_data.data_vars:\n",
    "                                    continue\n",
    "                                \n",
    "                                # Create dataset with renamed variable\n",
    "                                sensor_ds = xr.Dataset({\n",
    "                                    output_var: profile_data[input_var]\n",
    "                                })\n",
    "                                \n",
    "                                # Add depth coordinate if available\n",
    "                                if 'depth' in profile_data.coords:\n",
    "                                    sensor_ds = sensor_ds.assign_coords(depth=profile_data['depth'])\n",
    "                                \n",
    "                                # Remove unwanted variables\n",
    "                                for var in ['lat', 'lon', 'obs']:\n",
    "                                    if var in sensor_ds.coords:\n",
    "                                        sensor_ds = sensor_ds.drop_vars(var)\n",
    "                                    if var in sensor_ds.data_vars:\n",
    "                                        sensor_ds = sensor_ds.drop_vars(var)\n",
    "                                \n",
    "                                # Write file\n",
    "                                sensor_ds.to_netcdf(output_path)\n",
    "                                stats[output_var]['written'] += 1\n",
    "                            \n",
    "                        except Exception:\n",
    "                            continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n=== Processing Complete ===\")\n",
    "    for sensor, counts in stats.items():\n",
    "        print(f\"\\n{sensor}:\")\n",
    "        print(f\"  Attempted: {counts['attempted']}\")\n",
    "        print(f\"  Written: {counts['written']}\")\n",
    "        print(f\"  Skipped (already exist): {counts['skipped']}\")\n",
    "    \n",
    "    # Report files by year and sensor\n",
    "    print(\"\\n=== Files by Year ===\")\n",
    "    for year in range(2014, 2027):\n",
    "        output_dir = Path(f\"~/redux{year}\").expanduser()\n",
    "        if output_dir.exists():\n",
    "            sensor_counts = {}\n",
    "            for sensor in SENSOR_MAP.values():\n",
    "                count = len(list(output_dir.glob(f\"*_{sensor}_*.nc\")))\n",
    "                if count > 0:\n",
    "                    sensor_counts[sensor] = count\n",
    "            \n",
    "            if sensor_counts:\n",
    "                print(f\"\\n{year}:\")\n",
    "                for sensor, count in sensor_counts.items():\n",
    "                    print(f\"  {sensor}: {count}\")\n",
    "\n",
    "# Run the processing\n",
    "process_multi_sensor_redux()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222c3d1d-2a16-41bf-ac0f-88eade78fa5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTD dimensions: Frozen({'obs': 1597443})\n",
      "DO dimensions: Frozen({'obs': 10779154})\n",
      "\n",
      "CTD variables: ['corrected_dissolved_oxygen', 'corrected_dissolved_oxygen_qc_executed', 'corrected_dissolved_oxygen_qc_results', 'corrected_dissolved_oxygen_qartod_executed', 'do_fast_sample-corrected_dissolved_oxygen', 'corrected_dissolved_oxygen_qartod_results']\n",
      "DO variables: ['corrected_dissolved_oxygen_qc_executed', 'corrected_dissolved_oxygen', 'corrected_dissolved_oxygen_qc_results']\n",
      "\n",
      "First ascent: 2025-01-01T00:27:56.371564032 to 2025-01-01T01:10:54.460070400\n",
      "Duration: 2578.1 seconds\n",
      "\n",
      "--- Sample Rates ---\n",
      "CTD corrected_dissolved_oxygen: 2578 samples\n",
      "CTD do_fast_sample-corrected_dissolved_oxygen: 2578 samples\n",
      "DO corrected_dissolved_oxygen: 2579 samples\n",
      "\n",
      "--- Data Comparison ---\n",
      "CTD corrected_dissolved_oxygen: min=84.80, max=222.36, mean=121.23\n",
      "CTD do_fast_sample-corrected: min=84.80, max=222.36, mean=121.23\n",
      "DO corrected_dissolved_oxygen: min=84.80, max=222.63, mean=121.27\n",
      "\n",
      "Difference between CTD DO variables: max=0.000000, mean=0.000000\n",
      "Are they identical? True\n",
      "\n",
      "Difference CTD fast_sample vs DO file (first 2578 samples):\n",
      "  max=0.000000, mean=0.000000\n",
      "  Are they identical? True\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load files\n",
    "ctd_dir = Path.home() / 'ooidata/rca/sb/scalar/2025_ctd'\n",
    "do_dir = Path.home() / 'ooidata/rca/sb/scalar/2024_ctd'\n",
    "ctd_file = ctd_dir / 'deployment0012_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20250101T000000.308210-20250119T115959.698459.nc'\n",
    "do_file = do_dir / 'deployment0012_RS01SBPS-SF01A-2A-DOFSTA102-streamed-do_fast_sample_20241231T235959.308203-20250507T000000.827670.nc'\n",
    "\n",
    "ds_ctd = xr.open_dataset(ctd_file)\n",
    "ds_do = xr.open_dataset(do_file)\n",
    "\n",
    "print(\"CTD dimensions:\", ds_ctd.dims)\n",
    "print(\"DO dimensions:\", ds_do.dims)\n",
    "print(\"\\nCTD variables:\", [v for v in ds_ctd.data_vars if 'oxygen' in v.lower()])\n",
    "print(\"DO variables:\", [v for v in ds_do.data_vars if 'oxygen' in v.lower()])\n",
    "\n",
    "# Use 'obs' dimension instead of 'time'\n",
    "start_time = np.datetime64('2025-01-01T00:00:00')\n",
    "time = ds_ctd.time.values\n",
    "depth = ds_ctd.depth.values\n",
    "\n",
    "# Find indices after start_time\n",
    "idx_after = np.where(time >= start_time)[0]\n",
    "time_after = time[idx_after]\n",
    "depth_after = depth[idx_after]\n",
    "\n",
    "# Detect ascent (depth decreasing)\n",
    "depth_diff = np.diff(depth_after)\n",
    "\n",
    "# Find sustained ascent (at least 50 consecutive decreasing points)\n",
    "ascent_start_rel = None\n",
    "for i in range(len(depth_diff) - 50):\n",
    "    if np.all(depth_diff[i:i+50] < 0):\n",
    "        ascent_start_rel = i\n",
    "        break\n",
    "\n",
    "ascent_start = idx_after[ascent_start_rel]\n",
    "\n",
    "# Find end of ascent\n",
    "ascent_end = ascent_start\n",
    "for i in range(ascent_start_rel + 50, len(depth_diff)):\n",
    "    if depth_diff[i] >= 0:\n",
    "        ascent_end = idx_after[i]\n",
    "        break\n",
    "\n",
    "t_start = time[ascent_start]\n",
    "t_end = time[ascent_end]\n",
    "\n",
    "print(f\"\\nFirst ascent: {t_start} to {t_end}\")\n",
    "print(f\"Duration: {(t_end - t_start) / np.timedelta64(1, 's'):.1f} seconds\")\n",
    "\n",
    "# Extract data for ascent period using isel\n",
    "ctd_ascent = ds_ctd.isel(obs=slice(ascent_start, ascent_end))\n",
    "\n",
    "# For DO file, find matching time range\n",
    "do_time = ds_do.time.values\n",
    "do_idx = np.where((do_time >= t_start) & (do_time <= t_end))[0]\n",
    "do_ascent = ds_do.isel(obs=do_idx)\n",
    "\n",
    "# Get the three DO variables\n",
    "ctd_do1 = ctd_ascent['corrected_dissolved_oxygen'].values\n",
    "ctd_do2 = ctd_ascent['do_fast_sample-corrected_dissolved_oxygen'].values\n",
    "do_do = do_ascent['corrected_dissolved_oxygen'].values\n",
    "\n",
    "print(f\"\\n--- Sample Rates ---\")\n",
    "print(f\"CTD corrected_dissolved_oxygen: {len(ctd_do1)} samples\")\n",
    "print(f\"CTD do_fast_sample-corrected_dissolved_oxygen: {len(ctd_do2)} samples\")\n",
    "print(f\"DO corrected_dissolved_oxygen: {len(do_do)} samples\")\n",
    "\n",
    "print(f\"\\n--- Data Comparison ---\")\n",
    "print(f\"CTD corrected_dissolved_oxygen: min={np.nanmin(ctd_do1):.2f}, max={np.nanmax(ctd_do1):.2f}, mean={np.nanmean(ctd_do1):.2f}\")\n",
    "print(f\"CTD do_fast_sample-corrected: min={np.nanmin(ctd_do2):.2f}, max={np.nanmax(ctd_do2):.2f}, mean={np.nanmean(ctd_do2):.2f}\")\n",
    "print(f\"DO corrected_dissolved_oxygen: min={np.nanmin(do_do):.2f}, max={np.nanmax(do_do):.2f}, mean={np.nanmean(do_do):.2f}\")\n",
    "\n",
    "# Check if CTD variables are identical\n",
    "if len(ctd_do1) == len(ctd_do2):\n",
    "    diff = np.abs(ctd_do1 - ctd_do2)\n",
    "    print(f\"\\nDifference between CTD DO variables: max={np.nanmax(diff):.6f}, mean={np.nanmean(diff):.6f}\")\n",
    "    print(f\"Are they identical? {np.allclose(ctd_do1, ctd_do2, equal_nan=True)}\")\n",
    "\n",
    "# Compare CTD vs DO file - use minimum length\n",
    "n_compare = min(len(ctd_do2), len(do_do))\n",
    "diff = np.abs(ctd_do2[:n_compare] - do_do[:n_compare])\n",
    "print(f\"\\nDifference CTD fast_sample vs DO file (first {n_compare} samples):\")\n",
    "print(f\"  max={np.nanmax(diff):.6f}, mean={np.nanmean(diff):.6f}\")\n",
    "print(f\"  Are they identical? {np.allclose(ctd_do2[:n_compare], do_do[:n_compare], equal_nan=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e9c323-e840-4363-8cca-5f83ad06515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year   Density    DO         Salinity   Temperature\n",
      "--------------------------------------------------------\n",
      "2014   0          0          0          0         \n",
      "2015   659        659        659        659       \n",
      "2016   2953       2953       2953       2953      \n",
      "2017   1409       1409       1409       1409      \n",
      "2018   1849       1849       1849       1849      \n",
      "2019   2105       2105       2105       2105      \n",
      "2020   1281       1281       1281       1281      \n",
      "2021   2690       2690       2690       2690      \n",
      "2022   2193       2193       2193       2193      \n",
      "2023   785        785        785        785       \n",
      "2024   1802       1802       1802       1802      \n",
      "2025   2827       2827       2827       2827      \n",
      "2026   0          0          0          0         \n"
     ]
    }
   ],
   "source": [
    "# Count the number of profile files found in the shard output folders. The folder\n",
    "#   for year <yyyy> is called redux<yyyy>. \n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sensors = ['density', 'dissolvedoxygen', 'salinity', 'temperature']\n",
    "years = range(2014, 2027)\n",
    "\n",
    "print(f\"{'Year':<6} {'Density':<10} {'DO':<10} {'Salinity':<10} {'Temperature':<10}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for year in years:\n",
    "    redux_folder = Path.home() / f'redux{year}'\n",
    "    if redux_folder.exists():\n",
    "        counts = []\n",
    "        for sensor in sensors:\n",
    "            count = len(list(redux_folder.glob(f'RCA_sb_sp_{sensor}_*.nc')))\n",
    "            counts.append(count)\n",
    "        print(f\"{year:<6} {counts[0]:<10} {counts[1]:<10} {counts[2]:<10} {counts[3]:<10}\")\n",
    "    else:\n",
    "        print(f\"{year:<6} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8fe07f-fc26-466f-af8e-aa72f47f5cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year   Profiles  \n",
      "----------------\n",
      "2014   N/A       \n",
      "2015   659       \n",
      "2016   2953      \n",
      "2017   1409      \n",
      "2018   1855      \n",
      "2019   2105      \n",
      "2020   1281      \n",
      "2021   2973      \n",
      "2022   2359      \n",
      "2023   1397      \n",
      "2024   2298      \n",
      "2025   2827      \n",
      "2026   13        \n"
     ]
    }
   ],
   "source": [
    "# Determine the number of profiles in the profileIndices metadata resource\n",
    "#   The result is printed as a two-column table: year ~ profile count.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "profile_folder = Path.home() / 'profileIndices'\n",
    "years = range(2014, 2027)\n",
    "\n",
    "print(f\"{'Year':<6} {'Profiles':<10}\")\n",
    "print(\"-\" * 16)\n",
    "\n",
    "for year in years:\n",
    "    profile_file = profile_folder / f'RS01SBPS_profiles_{year}.csv'\n",
    "    if profile_file.exists():\n",
    "        df = pd.read_csv(profile_file)\n",
    "        count = len(df)\n",
    "        print(f\"{year:<6} {count:<10}\")\n",
    "    else:\n",
    "        print(f\"{year:<6} {'N/A':<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f412361-c268-4f05-bb77-b30dda9a3e21",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Year   Profiles      CTD profile count  \n",
    "--------------------------------------\n",
    "2014   N/A           N/A\n",
    "2015   659           659     \n",
    "2016   2953         2953      \n",
    "2017   1409         1409\n",
    "2018   1855         1849\n",
    "2019   2105         2105\n",
    "2020   1281         1281\n",
    "2021   2973         2690\n",
    "2022   2359         2193\n",
    "2023   1397          785\n",
    "2024   2298         1802\n",
    "2025   2827         2827\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
