{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd79491-9c9d-4d1d-ab0b-1d7a84bdace2",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "\n",
    "\n",
    "This notebook deals with transferring datasets from OOINET (and possibly other\n",
    "resources such as the PO-DAAC) to localhost.\n",
    "\n",
    "\n",
    "The data order is easily done manually although it gets a bit tedious if one does it in 1-year blocks.\n",
    "The resulting links are placed in a text file with one URL per line:\n",
    "\n",
    "```\n",
    "2015 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235914738Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2016 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235958368Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2017      https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260208T000033389Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2018 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/?\n",
    "2019 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/?\n",
    "2020 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/?\n",
    "2021 done https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235434950Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2022      https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235535508Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2023      https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235629121Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2024      https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235701343Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "2025      https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235802626Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
    "```\n",
    "\n",
    "We want the code in the cell below to read this file and go to each link in succession, \n",
    "downloading the data to a corresponding localhost folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32c824-f38e-4289-b8a0-5558640600ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 URLs to process\n",
      "\n",
      "=== URL 1/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235914738Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 23\n",
      "  Already downloaded: 23\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 2/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235958368Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 24\n",
      "  Already downloaded: 24\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 3/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260208T000033389Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 13\n",
      "  Already downloaded: 13\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 4/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235434950Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 22\n",
      "  Already downloaded: 22\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 5/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235535508Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 22\n",
      "  Already downloaded: 22\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 6/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235629121Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 12\n",
      "  Already downloaded: 12\n",
      "  Remaining to download: 0\n",
      "  All files complete, skipping\n",
      "\n",
      "=== URL 7/8 ===\n",
      "https://downloads.oceanobservatories.org/async_results/kilroy1618@gmail.com/20260207T235701343Z-RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample\n",
      "  Total .nc files: 23\n",
      "  Already downloaded: 7\n",
      "  Remaining to download: 16\n",
      "  [1/16] Downloading deployment0011_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20240529T120000.314467-20240617T235959.640407.nc to 2024_ctd/\n",
      "    Complete: 459.8 MB\n",
      "  [2/16] Downloading deployment0011_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20240618T000000.640518-20240712T115959.059289.nc to 2024_ctd/\n",
      "    Complete: 471.7 MB\n",
      "  [3/16] Downloading deployment0011_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20240712T120000.059402-20240731T115959.153324.nc to 2024_ctd/\n",
      "    Complete: 471.9 MB\n",
      "  [4/16] Downloading deployment0011_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20240731T120000.153538-20240809T063045.498432.nc to 2024_ctd/\n",
      "    Complete: 218.8 MB\n",
      "  [5/16] Downloading deployment0011_RS01SBPS-SF01A-2A-DOFSTA102-streamed-do_fast_sample_20231231T235959.766955-20240525T120000.414539.nc to 2023_ctd/\n",
      "    Complete: 641.9 MB\n",
      "  [6/16] Downloading deployment0011_RS01SBPS-SF01A-2A-DOFSTA102-streamed-do_fast_sample_20240525T115959.415261-20240809T063045.498432.nc to 2024_ctd/\n",
      "    Complete: 354.1 MB\n",
      "  [7/16] Downloading deployment0012_RS01SBPS-SF01A-2A-CTDPFA102-streamed-ctdpf_sbe43_sample_20240809T203132.739326-20240829T235959.714924.nc to 2024_ctd/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def parse_year_from_filename(filename):\n",
    "    \"\"\"Extract year from NetCDF filename.\"\"\"\n",
    "    pattern = r'_(\\d{4})\\d{2}\\d{2}T\\d{6}\\.\\d+-\\d{8}T\\d{6}\\.\\d+\\.nc$'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def is_file_complete(filepath):\n",
    "    \"\"\"Check if file exists and is complete (non-zero size).\"\"\"\n",
    "    if not filepath.exists():\n",
    "        return False\n",
    "    return filepath.stat().st_size > 0\n",
    "\n",
    "def download_file(url, destination):\n",
    "    \"\"\"Download a file from URL to destination.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Download to temporary file first\n",
    "        temp_file = destination.with_suffix('.tmp')\n",
    "        \n",
    "        with open(temp_file, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Rename to final name only if download completed\n",
    "        temp_file.rename(destination)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {e}\")\n",
    "        # Clean up temp file if it exists\n",
    "        if temp_file.exists():\n",
    "            temp_file.unlink()\n",
    "        return False\n",
    "\n",
    "def bulk_download():\n",
    "    \"\"\"Bulk download CTD files from URL list with restart tolerance.\"\"\"\n",
    "    \n",
    "    # Read URL list\n",
    "    url_list_file = Path(\"~/argosy/download_link_list.txt\").expanduser()\n",
    "    \n",
    "    if not url_list_file.exists():\n",
    "        print(f\"File not found: {url_list_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(url_list_file, 'r') as f:\n",
    "        urls = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"Found {len(urls)} URLs to process\\n\")\n",
    "    \n",
    "    # Base folder\n",
    "    base_folder = Path(\"~/ooidata/rca/sb/scalar\").expanduser()\n",
    "    \n",
    "    # Check that year folders exist\n",
    "    for year in range(2014, 2027):\n",
    "        year_folder = base_folder / f\"{year}_ctd\"\n",
    "        if not year_folder.exists():\n",
    "            print(f\"Destination folder does not exist: {year_folder}\")\n",
    "            print(\"Please create all required year folders before running download\")\n",
    "            return\n",
    "    \n",
    "    total_downloaded = 0\n",
    "    total_skipped = 0\n",
    "    total_already_complete = 0\n",
    "    \n",
    "    # Process each URL\n",
    "    for url_idx, url in enumerate(urls, 1):\n",
    "        print(f\"=== URL {url_idx}/{len(urls)} ===\")\n",
    "        print(f\"{url}\")\n",
    "        \n",
    "        try:\n",
    "            # Get directory listing\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML to find .nc files\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            links = soup.find_all('a')\n",
    "            \n",
    "            nc_files = []\n",
    "            for link in links:\n",
    "                href = link.get('href', '')\n",
    "                if href.endswith('.nc') and not href.endswith('.ncml'):\n",
    "                    nc_files.append(href)\n",
    "            \n",
    "            # Count already downloaded files\n",
    "            already_downloaded = 0\n",
    "            to_download = []\n",
    "            \n",
    "            for filename in nc_files:\n",
    "                year = parse_year_from_filename(filename)\n",
    "                if year is None:\n",
    "                    continue\n",
    "                    \n",
    "                dest_folder = base_folder / f\"{year}_ctd\"\n",
    "                dest_file = dest_folder / filename\n",
    "                \n",
    "                if is_file_complete(dest_file):\n",
    "                    already_downloaded += 1\n",
    "                else:\n",
    "                    to_download.append((filename, year))\n",
    "            \n",
    "            # Print diagnostics\n",
    "            print(f\"  Total .nc files: {len(nc_files)}\")\n",
    "            print(f\"  Already downloaded: {already_downloaded}\")\n",
    "            print(f\"  Remaining to download: {len(to_download)}\")\n",
    "            \n",
    "            total_already_complete += already_downloaded\n",
    "            \n",
    "            if len(to_download) == 0:\n",
    "                print(f\"  All files complete, skipping\\n\")\n",
    "                continue\n",
    "            \n",
    "            # Download remaining files\n",
    "            for file_idx, (filename, year) in enumerate(to_download, 1):\n",
    "                dest_folder = base_folder / f\"{year}_ctd\"\n",
    "                dest_file = dest_folder / filename\n",
    "                \n",
    "                file_url = url.rstrip('/') + '/' + filename\n",
    "                print(f\"  [{file_idx}/{len(to_download)}] Downloading {filename} to {year}_ctd/\")\n",
    "                \n",
    "                if download_file(file_url, dest_file):\n",
    "                    total_downloaded += 1\n",
    "                    file_size = dest_file.stat().st_size / (1024*1024)\n",
    "                    print(f\"    Complete: {file_size:.1f} MB\")\n",
    "                else:\n",
    "                    total_skipped += 1\n",
    "            \n",
    "            print()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing URL: {e}\\n\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"=== Download Summary ===\")\n",
    "    print(f\"Files already complete: {total_already_complete}\")\n",
    "    print(f\"Files newly downloaded: {total_downloaded}\")\n",
    "    print(f\"Files failed/skipped: {total_skipped}\")\n",
    "    \n",
    "    # Report files by year\n",
    "    print(\"\\nTotal files by year:\")\n",
    "    for year in range(2014, 2027):\n",
    "        year_folder = base_folder / f\"{year}_ctd\"\n",
    "        if year_folder.exists():\n",
    "            count = len(list(year_folder.glob(\"*.nc\")))\n",
    "            if count > 0:\n",
    "                print(f\"  {year}: {count} files\")\n",
    "\n",
    "# Run the bulk download\n",
    "bulk_download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e688345-2eb8-43ef-ae6c-0dce86bc49f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed136f6-77af-4328-aa24-eeda443b15d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07384f9b-7ff4-4ef2-afc6-ba1a039d5d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
